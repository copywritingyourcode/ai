2025-03-17 15:02:01,590 - root - INFO - Logging initialized
2025-03-17 15:02:01,590 - root - INFO - Starting Local AI Assistant
2025-03-17 15:02:01,590 - root - INFO - Initializing model manager
2025-03-17 15:02:01,598 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:02:01,598 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:02:01,598 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:02:01,600 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:02:01,600 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:02:02,592 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:02:02,592 - root - INFO - Initializing vector store
2025-03-17 15:02:02,635 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:02:02,705 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:02:02,705 - root - INFO - Initializing document loader
2025-03-17 15:02:02,708 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:02:02,712 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:02:02,712 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:02:02,712 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:07:02,083 - root - INFO - Logging initialized
2025-03-17 15:07:02,083 - root - INFO - Starting Local AI Assistant
2025-03-17 15:07:02,083 - root - INFO - Initializing model manager
2025-03-17 15:07:02,091 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:07:02,092 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:07:02,092 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:07:02,093 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:07:02,093 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:07:03,117 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:07:03,117 - root - INFO - Initializing vector store
2025-03-17 15:07:03,150 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:07:03,205 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:07:03,206 - root - INFO - Initializing document loader
2025-03-17 15:07:03,209 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:07:03,212 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:07:03,212 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:07:03,213 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:10:44,226 - root - INFO - Logging initialized
2025-03-17 15:10:44,226 - root - INFO - Starting Local AI Assistant
2025-03-17 15:10:44,226 - root - INFO - Initializing model manager
2025-03-17 15:10:44,234 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:10:44,235 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:10:44,235 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:10:44,237 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:10:44,237 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:10:45,914 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:10:45,915 - root - INFO - Initializing vector store
2025-03-17 15:10:45,960 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:10:46,021 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:10:46,021 - root - INFO - Initializing document loader
2025-03-17 15:10:46,024 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:10:46,027 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:10:46,028 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:10:46,028 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:14:23,407 - local_ai_assistant.cli.interface - INFO - Loading document: /Users/Ai/ai/local_ai_assistant/memory/PDF
2025-03-17 15:14:23,407 - local_ai_assistant.document.loader - ERROR - Unsupported file format: 
2025-03-17 15:14:33,275 - local_ai_assistant.cli.interface - INFO - Loading document: "/Users/Ai/ai/local_ai_assistant/memory/PDF"
2025-03-17 15:14:33,275 - local_ai_assistant.document.loader - ERROR - File not found: "/Users/Ai/ai/local_ai_assistant/memory/PDF"
2025-03-17 15:15:03,121 - root - INFO - Logging initialized
2025-03-17 15:15:03,121 - root - INFO - Starting Local AI Assistant
2025-03-17 15:15:03,122 - root - INFO - Initializing model manager
2025-03-17 15:15:03,130 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:15:03,130 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:15:03,131 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:15:03,136 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:15:03,137 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:15:04,228 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:15:04,228 - root - INFO - Initializing vector store
2025-03-17 15:15:04,273 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:15:04,332 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:15:04,332 - root - INFO - Initializing document loader
2025-03-17 15:15:04,335 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:15:04,338 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:15:04,338 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:15:04,339 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:15:29,044 - local_ai_assistant.cli.interface - INFO - Loading document: "/Users/Ai/ai/local_ai_assistant/memory/PDF"
2025-03-17 15:15:29,044 - local_ai_assistant.document.loader - ERROR - File not found: "/Users/Ai/ai/local_ai_assistant/memory/PDF"
2025-03-17 15:16:29,524 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:16:29,525 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:16:29,525 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:16:29,527 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:16:29,527 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:16:30,349 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:16:30,751 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:16:36,523 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:16:36,541 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:16:41,743 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:16:41,744 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:16:41,744 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:16:41,746 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:16:41,746 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:16:42,592 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:16:42,630 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:16:46,350 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:16:46,369 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:17:03,398 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:19:41,497 - root - INFO - Logging initialized
2025-03-17 15:19:41,497 - root - INFO - Starting Local AI Assistant
2025-03-17 15:19:41,497 - root - INFO - Initializing model manager
2025-03-17 15:19:41,506 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:19:41,506 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:19:41,506 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:19:41,507 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:19:41,508 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 16, 42, 590763, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:19:41,508 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:19:42,743 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:19:42,744 - root - INFO - Initializing vector store
2025-03-17 15:19:42,794 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:19:42,855 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:19:42,855 - root - INFO - Initializing document loader
2025-03-17 15:19:42,858 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:19:42,862 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:19:42,862 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:19:42,862 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:20:09,079 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:20:09,079 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:20:09,079 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:20:09,081 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:20:09,082 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 19, 42, 742352, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:20:09,082 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:20:09,931 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:20:09,980 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:20:13,985 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:20:14,004 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:21:19,319 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:23:05,730 - root - INFO - Logging initialized
2025-03-17 15:23:05,730 - root - INFO - Starting Local AI Assistant
2025-03-17 15:23:05,730 - root - INFO - Initializing model manager
2025-03-17 15:23:05,736 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:23:05,737 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:23:05,737 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:23:05,739 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:23:05,739 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 20, 9, 929691, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:23:05,739 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:23:06,610 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:23:06,611 - root - INFO - Initializing vector store
2025-03-17 15:23:06,653 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:23:06,707 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:23:06,707 - root - INFO - Initializing document loader
2025-03-17 15:23:06,710 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:23:06,713 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:23:06,713 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:23:06,713 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:23:13,439 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:23:13,439 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:23:13,439 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:23:13,442 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:23:13,442 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 23, 6, 608350, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:23:13,442 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:23:14,275 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:23:14,320 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:23:18,040 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:23:18,059 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:23:27,940 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:24:04,289 - root - INFO - Logging initialized
2025-03-17 15:24:04,289 - root - INFO - Starting Local AI Assistant
2025-03-17 15:24:04,289 - root - INFO - Initializing model manager
2025-03-17 15:24:04,294 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:24:04,294 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:24:04,294 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:24:04,295 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:24:04,296 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 23, 14, 269089, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:24:04,296 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:24:05,243 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:24:05,243 - root - INFO - Initializing vector store
2025-03-17 15:24:05,271 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:24:05,335 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:24:05,335 - root - INFO - Initializing document loader
2025-03-17 15:24:05,339 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:24:05,342 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:24:05,342 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:24:05,342 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:24:10,575 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:24:10,576 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:24:10,576 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:24:10,577 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:24:10,577 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 24, 5, 242857, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:24:10,577 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:24:11,419 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:24:11,440 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:24:27,982 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:24:28,083 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:25:00,976 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:27:39,506 - root - INFO - Logging initialized
2025-03-17 15:27:39,506 - root - INFO - Starting Local AI Assistant
2025-03-17 15:27:39,506 - root - INFO - Initializing model manager
2025-03-17 15:27:39,514 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:27:39,516 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:27:39,516 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:27:39,518 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:27:39,519 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 24, 11, 418634, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:27:39,519 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:27:43,204 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:27:43,205 - root - INFO - Initializing vector store
2025-03-17 15:27:43,248 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:27:43,304 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:27:43,304 - root - INFO - Initializing document loader
2025-03-17 15:27:43,308 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:27:43,311 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:27:43,311 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:27:43,311 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:27:50,054 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:27:50,055 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 27, 43, 203186, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:28:03,597 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:28:03,597 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:28:03,597 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:28:03,600 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:28:03,601 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 27, 43, 203186, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:28:03,601 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:28:04,476 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:28:04,516 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:28:26,967 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:28:27,009 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:28:40,600 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:28:58,206 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:28:58,240 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:29:20,728 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:29:50,436 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:30:07,814 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:30:07,847 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:30:27,000 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:30:50,890 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:30:50,892 - local_ai_assistant.cli.interface - ERROR - Error generating response: 'message'
Traceback (most recent call last):
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 427, in _process_query
    print(f"- {issue['category']}: {issue['message']}")
KeyError: 'message'
2025-03-17 15:30:50,910 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:30:57,441 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:30:57,465 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:31:05,776 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:31:28,153 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:31:28,193 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:31:50,618 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:33:27,539 - local_ai_assistant.cli.interface - INFO - Loading document: local_ai_assistant/memory/PDF/How Delta-Neutral Trading Works- Funding Rate Approach.pdf
2025-03-17 15:33:27,570 - local_ai_assistant.document.loader - INFO - Loaded document: How Delta-Neutral Trading Works- Funding Rate Approach.pdf (ID: 0fca003f-386f-46ab-8e11-f2c73413c240)
2025-03-17 15:34:04,919 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:34:08,425 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:34:08,442 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:34:24,971 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:34:30,881 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:34:30,902 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:35:02,630 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:35:06,485 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:35:06,503 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:35:25,469 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:35:35,660 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:35:35,685 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:35:45,523 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:36:08,827 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:36:08,828 - local_ai_assistant.cli.interface - ERROR - Error generating response: 'message'
Traceback (most recent call last):
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 427, in _process_query
    print(f"- {issue['category']}: {issue['message']}")
KeyError: 'message'
2025-03-17 15:36:24,019 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 15:36:38,428 - root - INFO - Logging initialized
2025-03-17 15:36:38,428 - root - INFO - Starting Local AI Assistant
2025-03-17 15:36:38,428 - root - INFO - Initializing model manager
2025-03-17 15:36:38,435 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:36:38,435 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:36:38,436 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:36:38,437 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:36:38,437 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 28, 4, 475140, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:36:38,438 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:36:40,344 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:36:40,345 - root - INFO - Initializing vector store
2025-03-17 15:36:40,390 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:36:40,446 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:36:40,446 - root - INFO - Initializing document loader
2025-03-17 15:36:40,450 - local_ai_assistant.document.loader - INFO - Loaded 1 documents from data/documents/documents.json
2025-03-17 15:36:40,450 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:36:40,453 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:36:40,453 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:36:40,453 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:37:32,568 - local_ai_assistant.cli.interface - INFO - Loading document: local_ai_assistant/memory/PDF/Programmable Bitcoin Is Here- A Turing-complete Bridgeless Bitcoin Execution Lay.pdf
2025-03-17 15:37:32,605 - local_ai_assistant.document.loader - INFO - Loaded document: Programmable Bitcoin Is Here- A Turing-complete Bridgeless Bitcoin Execution Lay.pdf (ID: 9809e25e-d046-45dd-a457-c59c72b44565)
2025-03-17 15:37:45,573 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:37:45,574 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:37:45,574 - local_ai_assistant.models.model_manager - INFO - Loading model: gemma3:27b
2025-03-17 15:37:45,576 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:37:45,576 - local_ai_assistant.models.model_manager - ERROR - Unexpected response format from Ollama: models=[Model(model='gemma3:27b', modified_at=datetime.datetime(2025, 3, 17, 15, 36, 40, 341619, tzinfo=TzInfo(+11:00)), digest='30ddded7fba6d6f9c2f26661e2feba2d7a26a75e20a817538c41c3716d92609d', size=17396936887, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='27.4B', quantization_level='Q4_K_M')), Model(model='deepseek-rag:latest', modified_at=datetime.datetime(2025, 3, 12, 23, 10, 14, 43752, tzinfo=TzInfo(+11:00)), digest='53fc716d40e35e8b1882a3acc376766257c25e6eb563f341eb03ca4dfe988880', size=4683075572, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='qwen:latest', modified_at=datetime.datetime(2025, 3, 12, 22, 17, 29, 588145, tzinfo=TzInfo(+11:00)), digest='d53d04290064542e5f12ccfb0055785b7751264dc6bbb06c04c559c57e07496a', size=2330093361, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='4B', quantization_level='Q4_0')), Model(model='deepseek-r1:7b', modified_at=datetime.datetime(2025, 3, 12, 17, 14, 3, 721614, tzinfo=TzInfo(+11:00)), digest='0a8c266910232fd3291e71e5ba1e058cc5af9d411192cf88b6d30e92b6e73163', size=4683075271, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='7.6B', quantization_level='Q4_K_M')), Model(model='nomic-embed-text:latest', modified_at=datetime.datetime(2025, 3, 12, 15, 21, 25, 207835, tzinfo=TzInfo(+11:00)), digest='0a109f422b47e3a30ba2b10eca18548e944e8a23073ee3f3e947efcf3c45e59f', size=274302450, details=ModelDetails(parent_model='', format='gguf', family='nomic-bert', families=['nomic-bert'], parameter_size='137M', quantization_level='F16')), Model(model='qwq:latest', modified_at=datetime.datetime(2025, 3, 11, 22, 42, 52, 527895, tzinfo=TzInfo(+11:00)), digest='cc1091b0e276012ba4c1662ea103be2c87a1543d2ee435eb5715b37b9b680d27', size=19851349390, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='llama3.2:latest', modified_at=datetime.datetime(2025, 3, 11, 18, 37, 19, 828359, tzinfo=TzInfo(+11:00)), digest='a80c4f17acd55265feec403c7aef86be0c25983ab279d83f3bcd3abbcb5b8b72', size=2019393189, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='3.2B', quantization_level='Q4_K_M'))]
2025-03-17 15:37:45,576 - local_ai_assistant.models.model_manager - INFO - Pulling model: gemma3:27b
2025-03-17 15:37:46,493 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/pull "HTTP/1.1 200 OK"
2025-03-17 15:37:46,541 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:38:42,107 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:38:42,179 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:39:26,651 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:40:33,274 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:40:33,275 - local_ai_assistant.cli.interface - ERROR - Error generating response: 'message'
Traceback (most recent call last):
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 427, in _process_query
    print(f"- {issue['category']}: {issue['message']}")
KeyError: 'message'
2025-03-17 15:40:33,293 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:40:44,523 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:40:44,549 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:41:06,256 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:41:17,080 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:41:17,107 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:41:36,459 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:42:47,583 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:42:47,656 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:43:21,213 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:44:13,477 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 15:44:13,480 - local_ai_assistant.cli.interface - ERROR - Error generating response: 'message'
Traceback (most recent call last):
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 427, in _process_query
    print(f"- {issue['category']}: {issue['message']}")
KeyError: 'message'
2025-03-17 15:54:26,016 - root - INFO - Logging initialized
2025-03-17 15:54:26,016 - root - INFO - Starting Local AI Assistant
2025-03-17 15:54:26,016 - root - INFO - Initializing model manager
2025-03-17 15:56:29,168 - root - INFO - Logging initialized
2025-03-17 15:56:29,168 - root - INFO - Starting Local AI Assistant
2025-03-17 15:56:29,168 - root - INFO - Initializing model manager
2025-03-17 15:56:29,252 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:56:29,253 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:56:29,254 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:56:29,254 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 15:56:29,254 - root - INFO - Initializing vector store
2025-03-17 15:56:29,277 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:56:29,328 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:56:29,328 - root - INFO - Initializing document loader
2025-03-17 15:56:29,331 - local_ai_assistant.document.loader - INFO - Loaded 2 documents from data/documents/documents.json
2025-03-17 15:56:29,331 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:56:29,334 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:56:29,334 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:56:29,334 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:58:42,268 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:58:54,533 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 15:59:05,541 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:59:05,541 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:59:05,544 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:59:05,544 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 15:59:05,878 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:59:06,702 - local_ai_assistant.memory.vector_store - ERROR - Error getting recent messages: query() got an unexpected keyword argument 'order_by'
2025-03-17 15:59:07,548 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:59:08,256 - local_ai_assistant.memory.vector_store - ERROR - Error getting recent messages: query() got an unexpected keyword argument 'order_by'
2025-03-17 15:59:08,289 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:59:08,293 - local_ai_assistant.models.model_manager - ERROR - Error generating text: generate() got an unexpected keyword argument 'temperature'
2025-03-17 15:59:08,305 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:59:21,820 - root - INFO - Logging initialized
2025-03-17 15:59:21,820 - root - INFO - Starting Local AI Assistant
2025-03-17 15:59:21,821 - root - INFO - Initializing model manager
2025-03-17 15:59:21,903 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:59:21,904 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:59:21,906 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:59:21,906 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 15:59:21,906 - root - INFO - Initializing vector store
2025-03-17 15:59:21,930 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:59:21,981 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:59:21,981 - root - INFO - Initializing document loader
2025-03-17 15:59:21,984 - local_ai_assistant.document.loader - INFO - Loaded 2 documents from data/documents/documents.json
2025-03-17 15:59:21,984 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:59:21,987 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:59:21,987 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:59:21,987 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 15:59:41,162 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:59:41,162 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:59:41,165 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:59:41,166 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 15:59:41,201 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:59:41,220 - local_ai_assistant.memory.vector_store - ERROR - Error getting recent messages: query() got an unexpected keyword argument 'order_by'
2025-03-17 15:59:41,239 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:59:41,243 - local_ai_assistant.models.model_manager - ERROR - Error generating text: generate() got an unexpected keyword argument 'temperature'
2025-03-17 15:59:41,268 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 15:59:54,830 - root - INFO - Logging initialized
2025-03-17 15:59:54,830 - root - INFO - Starting Local AI Assistant
2025-03-17 15:59:54,830 - root - INFO - Initializing model manager
2025-03-17 15:59:54,903 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:59:54,904 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 15:59:54,906 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 15:59:54,907 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 15:59:54,907 - root - INFO - Initializing vector store
2025-03-17 15:59:54,931 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 15:59:54,984 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 15:59:54,984 - root - INFO - Initializing document loader
2025-03-17 15:59:54,987 - local_ai_assistant.document.loader - INFO - Loaded 2 documents from data/documents/documents.json
2025-03-17 15:59:54,987 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 15:59:54,990 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 15:59:54,990 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 15:59:54,990 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:00:10,199 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:00:10,199 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:00:10,203 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:00:10,204 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:00:10,242 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:00:10,258 - local_ai_assistant.memory.vector_store - ERROR - Error getting recent messages: query() got an unexpected keyword argument 'order_by'
2025-03-17 16:00:10,275 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:00:10,279 - local_ai_assistant.models.model_manager - ERROR - Error generating text: generate() got an unexpected keyword argument 'temperature'
2025-03-17 16:00:10,303 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:00:45,090 - local_ai_assistant.memory.vector_store - ERROR - Error getting recent messages: query() got an unexpected keyword argument 'order_by'
2025-03-17 16:01:20,641 - root - INFO - Logging initialized
2025-03-17 16:01:20,641 - root - INFO - Starting Local AI Assistant
2025-03-17 16:01:20,641 - root - INFO - Initializing model manager
2025-03-17 16:01:20,718 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:01:20,719 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:01:20,720 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:01:20,720 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:01:20,720 - root - INFO - Initializing vector store
2025-03-17 16:01:20,744 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:01:20,794 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:01:20,794 - root - INFO - Initializing document loader
2025-03-17 16:01:20,797 - local_ai_assistant.document.loader - INFO - Loaded 2 documents from data/documents/documents.json
2025-03-17 16:01:20,797 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:01:20,800 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:01:20,800 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:01:20,800 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:01:31,893 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:01:31,893 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:01:31,895 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:01:31,895 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:01:31,930 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:01:31,958 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:01:36,652 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:01:36,669 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:00,544 - root - INFO - Logging initialized
2025-03-17 16:02:00,544 - root - INFO - Starting Local AI Assistant
2025-03-17 16:02:00,544 - root - INFO - Initializing model manager
2025-03-17 16:02:00,630 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:00,630 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:02:00,634 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:00,634 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:02:00,634 - root - INFO - Initializing vector store
2025-03-17 16:02:00,658 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:02:00,709 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:02:00,710 - root - INFO - Initializing document loader
2025-03-17 16:02:00,713 - local_ai_assistant.document.loader - INFO - Loaded 2 documents from data/documents/documents.json
2025-03-17 16:02:00,713 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:02:00,716 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:02:00,716 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:02:00,716 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:02:00,718 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:02:02,739 - root - INFO - Logging initialized
2025-03-17 16:02:02,739 - root - INFO - Starting Local AI Assistant
2025-03-17 16:02:02,739 - root - INFO - Initializing model manager
2025-03-17 16:02:02,814 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:02,814 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:02:02,816 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:02,816 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:02:02,816 - root - INFO - Initializing vector store
2025-03-17 16:02:02,840 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:02:02,890 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:02:02,890 - root - INFO - Initializing document loader
2025-03-17 16:02:02,893 - local_ai_assistant.document.loader - INFO - Loaded 2 documents from data/documents/documents.json
2025-03-17 16:02:02,893 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:02:02,896 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:02:02,896 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:02:02,896 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:02:02,900 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:02:05,040 - root - INFO - Logging initialized
2025-03-17 16:02:05,040 - root - INFO - Starting Local AI Assistant
2025-03-17 16:02:05,040 - root - INFO - Initializing model manager
2025-03-17 16:02:05,118 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:05,118 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:02:05,121 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:05,121 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:02:05,121 - root - INFO - Initializing vector store
2025-03-17 16:02:05,146 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:02:05,199 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:02:05,199 - root - INFO - Initializing document loader
2025-03-17 16:02:05,202 - local_ai_assistant.document.loader - INFO - Loaded 2 documents from data/documents/documents.json
2025-03-17 16:02:05,202 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:02:05,206 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:02:05,206 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:02:05,206 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:02:05,208 - local_ai_assistant.cli.interface - INFO - Loading document: sample_document.txt
2025-03-17 16:02:05,209 - local_ai_assistant.document.loader - INFO - Loaded document: sample_document.txt (ID: d675ac4b-b844-4b5d-aa61-766fa531e5d5)
2025-03-17 16:02:05,213 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:02:05,214 - local_ai_assistant.document.indexer - INFO - Created 4 chunks from document
2025-03-17 16:02:05,255 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:05,278 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:05,290 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:05,299 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:05,315 - local_ai_assistant.document.indexer - INFO - Indexed document d675ac4b-b844-4b5d-aa61-766fa531e5d5 with 4 chunks
2025-03-17 16:02:05,316 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:02:07,216 - root - INFO - Logging initialized
2025-03-17 16:02:07,217 - root - INFO - Starting Local AI Assistant
2025-03-17 16:02:07,217 - root - INFO - Initializing model manager
2025-03-17 16:02:07,291 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:07,291 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:02:07,294 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:07,294 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:02:07,294 - root - INFO - Initializing vector store
2025-03-17 16:02:07,318 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:02:07,371 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:02:07,372 - root - INFO - Initializing document loader
2025-03-17 16:02:07,375 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:02:07,375 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:02:07,378 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:02:07,378 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:02:07,378 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:02:07,380 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:02:09,408 - root - INFO - Logging initialized
2025-03-17 16:02:09,409 - root - INFO - Starting Local AI Assistant
2025-03-17 16:02:09,409 - root - INFO - Initializing model manager
2025-03-17 16:02:09,491 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:09,491 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:02:09,494 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:09,494 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:02:09,494 - root - INFO - Initializing vector store
2025-03-17 16:02:09,517 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:02:09,569 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:02:09,569 - root - INFO - Initializing document loader
2025-03-17 16:02:09,572 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:02:09,572 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:02:09,576 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:02:09,576 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:02:09,576 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:02:09,579 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:02:11,579 - root - INFO - Logging initialized
2025-03-17 16:02:11,579 - root - INFO - Starting Local AI Assistant
2025-03-17 16:02:11,579 - root - INFO - Initializing model manager
2025-03-17 16:02:11,660 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:11,660 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:02:11,665 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:11,666 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:02:11,666 - root - INFO - Initializing vector store
2025-03-17 16:02:11,689 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:02:11,739 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:02:11,740 - root - INFO - Initializing document loader
2025-03-17 16:02:11,743 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:02:11,743 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:02:11,746 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:02:11,746 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:02:11,746 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:02:11,748 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:02:11,749 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:02:13,746 - root - INFO - Logging initialized
2025-03-17 16:02:13,746 - root - INFO - Starting Local AI Assistant
2025-03-17 16:02:13,746 - root - INFO - Initializing model manager
2025-03-17 16:02:13,825 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:13,825 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:02:13,827 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:13,827 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:02:13,827 - root - INFO - Initializing vector store
2025-03-17 16:02:13,851 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:02:13,901 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:02:13,901 - root - INFO - Initializing document loader
2025-03-17 16:02:13,904 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:02:13,904 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:02:13,907 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:02:13,907 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:02:13,907 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:02:13,918 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:13,918 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:02:13,920 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:02:13,920 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:02:13,963 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:13,992 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:22,187 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:02:22,210 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:28,608 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:02:33,895 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:33,908 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:39,468 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:02:39,496 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:02:56,290 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:02:56,293 - local_ai_assistant.cli.interface - ERROR - Error generating response: 'message'
Traceback (most recent call last):
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 700, in _process_query
    self.console.print(f"- {issue['category']}: {issue['message']}", style=self.debug_style)
KeyError: 'message'
2025-03-17 16:02:56,298 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:03:47,618 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:03:47,636 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:03:52,175 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:03:52,192 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:03:57,751 - root - INFO - Logging initialized
2025-03-17 16:03:57,751 - root - INFO - Starting Local AI Assistant
2025-03-17 16:03:57,751 - root - INFO - Initializing model manager
2025-03-17 16:03:57,828 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:03:57,829 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:03:57,834 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:03:57,835 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:03:57,835 - root - INFO - Initializing vector store
2025-03-17 16:03:57,860 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:03:57,913 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:03:57,913 - root - INFO - Initializing document loader
2025-03-17 16:03:57,916 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:03:57,916 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:03:57,920 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:03:57,920 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:03:57,920 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:04:02,465 - root - INFO - Logging initialized
2025-03-17 16:04:02,465 - root - INFO - Starting Local AI Assistant
2025-03-17 16:04:02,465 - root - INFO - Initializing model manager
2025-03-17 16:04:02,552 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:04:02,552 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:04:02,556 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:04:02,556 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:04:02,556 - root - INFO - Initializing vector store
2025-03-17 16:04:02,581 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:04:02,640 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:04:02,640 - root - INFO - Initializing document loader
2025-03-17 16:04:02,643 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:04:02,643 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:04:02,647 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:04:02,647 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:04:02,647 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:04:02,665 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:04:02,666 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:04:02,668 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:04:02,668 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:04:02,701 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:04:08,771 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:04:08,790 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:04:08,800 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:04:16,046 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:04:33,147 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:04:33,150 - local_ai_assistant.cli.interface - ERROR - Error in CLI: Failed to get style 'error'; unable to parse 'error' as color; 'error' is not a valid color
Traceback (most recent call last):
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 146, in run
    self._process_query(user_input)
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 629, in _process_query
    self.console.print(f"Error generating response: {str(e)}", style="error")
  File "/Users/evanng/Library/Python/3.9/lib/python/site-packages/rich/console.py", line 1705, in print
    render(renderable, render_options), self.get_style(style)
  File "/Users/evanng/Library/Python/3.9/lib/python/site-packages/rich/console.py", line 1482, in get_style
    raise errors.MissingStyle(
rich.errors.MissingStyle: Failed to get style 'error'; unable to parse 'error' as color; 'error' is not a valid color
2025-03-17 16:04:43,951 - root - INFO - Logging initialized
2025-03-17 16:04:43,951 - root - INFO - Starting Local AI Assistant
2025-03-17 16:04:43,951 - root - INFO - Initializing model manager
2025-03-17 16:04:44,040 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:04:44,041 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:04:44,044 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:04:44,044 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:04:44,044 - root - INFO - Initializing vector store
2025-03-17 16:04:44,069 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:04:44,122 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:04:44,122 - root - INFO - Initializing document loader
2025-03-17 16:04:44,126 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:04:44,126 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:04:44,129 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:04:44,129 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:04:44,129 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:04:51,437 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:04:51,437 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:04:51,439 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:04:51,439 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:04:51,471 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:04:57,002 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:04:57,017 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:04:57,026 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:04:57,038 - local_ai_assistant.cli.interface - ERROR - Error in CLI: Failed to get style 'error'; unable to parse 'error' as color; 'error' is not a valid color
Traceback (most recent call last):
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 146, in run
    self._process_query(user_input)
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 629, in _process_query
    self.console.print(f"Error generating response: {str(e)}", style="error")
  File "/Users/evanng/Library/Python/3.9/lib/python/site-packages/rich/console.py", line 1705, in print
    render(renderable, render_options), self.get_style(style)
  File "/Users/evanng/Library/Python/3.9/lib/python/site-packages/rich/console.py", line 1482, in get_style
    raise errors.MissingStyle(
rich.errors.MissingStyle: Failed to get style 'error'; unable to parse 'error' as color; 'error' is not a valid color
2025-03-17 16:06:58,802 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:06:58,802 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:06:58,805 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:06:58,805 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:06:58,840 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:07:06,390 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:07:06,405 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:07:06,414 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:07:15,775 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:07:35,620 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:07:35,632 - local_ai_assistant.cli.interface - ERROR - Error in CLI: Failed to get style 'error'; unable to parse 'error' as color; 'error' is not a valid color
Traceback (most recent call last):
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 146, in run
    self._process_query(user_input)
  File "/Users/Ai/ai/local_ai_assistant/cli/interface.py", line 629, in _process_query
    self.console.print(f"Error generating response: {str(e)}", style="error")
  File "/Users/evanng/Library/Python/3.9/lib/python/site-packages/rich/console.py", line 1705, in print
    render(renderable, render_options), self.get_style(style)
  File "/Users/evanng/Library/Python/3.9/lib/python/site-packages/rich/console.py", line 1482, in get_style
    raise errors.MissingStyle(
rich.errors.MissingStyle: Failed to get style 'error'; unable to parse 'error' as color; 'error' is not a valid color
2025-03-17 16:10:11,719 - root - INFO - Logging initialized
2025-03-17 16:10:11,719 - root - INFO - Starting Local AI Assistant
2025-03-17 16:10:11,719 - root - INFO - Initializing model manager
2025-03-17 16:10:11,795 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:10:11,795 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:10:11,798 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:10:11,798 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:10:11,798 - root - INFO - Initializing vector store
2025-03-17 16:10:11,822 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:10:11,875 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:10:11,875 - root - INFO - Initializing document loader
2025-03-17 16:10:11,878 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:10:11,878 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:10:19,291 - root - INFO - Logging initialized
2025-03-17 16:10:19,291 - root - INFO - Starting Local AI Assistant
2025-03-17 16:10:19,291 - root - INFO - Initializing model manager
2025-03-17 16:10:19,377 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:10:19,377 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:10:19,380 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:10:19,380 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:10:19,380 - root - INFO - Initializing vector store
2025-03-17 16:10:19,406 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:10:19,458 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:10:19,459 - root - INFO - Initializing document loader
2025-03-17 16:10:19,462 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:10:19,462 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:10:57,955 - root - INFO - Logging initialized
2025-03-17 16:10:57,955 - root - INFO - Starting Local AI Assistant
2025-03-17 16:10:57,955 - root - INFO - Initializing model manager
2025-03-17 16:10:58,042 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:10:58,042 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:10:58,048 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:10:58,048 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:10:58,048 - root - INFO - Initializing vector store
2025-03-17 16:10:58,075 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:10:58,128 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:10:58,128 - root - INFO - Initializing document loader
2025-03-17 16:10:58,131 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:10:58,131 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:10:58,137 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:10:58,137 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:10:58,137 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:10:58,157 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:10:58,157 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:10:58,159 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:10:58,159 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:10:58,197 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:10,379 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:11:10,399 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:10,414 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:10,421 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:11:20,739 - root - INFO - Logging initialized
2025-03-17 16:11:20,739 - root - INFO - Starting Local AI Assistant
2025-03-17 16:11:20,739 - root - INFO - Initializing model manager
2025-03-17 16:11:20,826 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:11:20,826 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:11:20,829 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:11:20,830 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:11:20,830 - root - INFO - Initializing vector store
2025-03-17 16:11:20,855 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:11:20,921 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:11:20,921 - root - INFO - Initializing document loader
2025-03-17 16:11:20,924 - local_ai_assistant.document.loader - INFO - Loaded 3 documents from data/documents/documents.json
2025-03-17 16:11:20,924 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:11:20,931 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:11:20,931 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:11:20,931 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:11:20,933 - local_ai_assistant.cli.interface - INFO - Loading document: sample_document.txt
2025-03-17 16:11:20,934 - local_ai_assistant.document.loader - INFO - Loaded document: sample_document.txt (ID: 6cca782c-0864-4a65-82f4-f49a3e27e400)
2025-03-17 16:11:20,938 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:11:20,938 - local_ai_assistant.document.indexer - INFO - Created 4 chunks from document
2025-03-17 16:11:20,995 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:21,014 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:21,030 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:21,042 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:21,060 - local_ai_assistant.document.indexer - INFO - Indexed document 6cca782c-0864-4a65-82f4-f49a3e27e400 with 4 chunks
2025-03-17 16:11:21,068 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:11:21,068 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:11:21,070 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:11:21,070 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:11:21,089 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:26,750 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:11:26,766 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:26,773 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:26,788 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:33,309 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:11:33,326 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:33,335 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:11:33,341 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:11:42,935 - root - INFO - Logging initialized
2025-03-17 16:11:42,936 - root - INFO - Starting Local AI Assistant
2025-03-17 16:11:42,936 - root - INFO - Initializing model manager
2025-03-17 16:11:43,016 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:11:43,016 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:11:43,018 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:11:43,018 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:11:43,018 - root - INFO - Initializing vector store
2025-03-17 16:11:43,047 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:11:43,103 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:11:43,103 - root - INFO - Initializing document loader
2025-03-17 16:11:43,107 - local_ai_assistant.document.loader - INFO - Loaded 4 documents from data/documents/documents.json
2025-03-17 16:11:43,107 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:11:43,113 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:11:43,113 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:11:43,113 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:11:43,118 - local_ai_assistant.cli.interface - INFO - Debug mode: True
2025-03-17 16:11:43,133 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:11:43,134 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:12:22,733 - root - INFO - Logging initialized
2025-03-17 16:12:22,733 - root - INFO - Starting Local AI Assistant
2025-03-17 16:12:22,733 - root - INFO - Initializing model manager
2025-03-17 16:12:22,823 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:12:22,824 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:12:22,825 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:12:22,825 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:12:22,825 - root - INFO - Initializing vector store
2025-03-17 16:12:22,851 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:12:22,904 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:12:22,904 - root - INFO - Initializing document loader
2025-03-17 16:12:22,908 - local_ai_assistant.document.loader - INFO - Loaded 4 documents from data/documents/documents.json
2025-03-17 16:12:22,908 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:12:22,914 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:12:22,914 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:12:22,914 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:12:33,722 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:12:38,032 - local_ai_assistant.cli.interface - INFO - Thinking display: False
2025-03-17 16:12:40,919 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:12:51,104 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:12:51,104 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:12:51,107 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:12:51,108 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:12:51,162 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:26,912 - root - INFO - Logging initialized
2025-03-17 16:15:26,912 - root - INFO - Starting Local AI Assistant
2025-03-17 16:15:26,912 - root - INFO - Initializing model manager
2025-03-17 16:15:26,987 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:15:26,987 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:15:26,989 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:15:26,989 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:15:26,989 - root - INFO - Initializing vector store
2025-03-17 16:15:27,014 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:15:27,068 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:15:27,068 - root - INFO - Initializing document loader
2025-03-17 16:15:27,071 - local_ai_assistant.document.loader - INFO - Loaded 4 documents from data/documents/documents.json
2025-03-17 16:15:27,071 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:15:27,077 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:15:27,077 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:15:27,077 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:15:27,081 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:15:27,097 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:15:27,097 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:15:27,099 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:15:27,099 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:15:27,139 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:34,137 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:15:34,154 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:34,162 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:34,176 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:43,529 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:15:43,545 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:43,555 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:43,567 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:52,682 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:15:52,698 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:52,708 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:52,713 - local_ai_assistant.cli.interface - INFO - Loading document: test_document.txt
2025-03-17 16:15:52,714 - local_ai_assistant.document.loader - INFO - Loaded document: test_document.txt (ID: 9938a032-98af-4b7e-afe4-4b033755992b)
2025-03-17 16:15:52,719 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:15:52,719 - local_ai_assistant.document.indexer - INFO - Created 1 chunks from document
2025-03-17 16:15:52,730 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:52,733 - local_ai_assistant.document.indexer - INFO - Indexed document 9938a032-98af-4b7e-afe4-4b033755992b with 1 chunks
2025-03-17 16:15:52,741 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:57,898 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:15:57,915 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:57,921 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:15:57,934 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:04,225 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:16:04,243 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:04,253 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:04,259 - local_ai_assistant.cli.interface - INFO - Thinking display: False
2025-03-17 16:16:04,259 - local_ai_assistant.cli.interface - INFO - Debug mode: True
2025-03-17 16:16:04,268 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:12,205 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:16:12,224 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:12,233 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:12,247 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:18,282 - root - INFO - Logging initialized
2025-03-17 16:16:18,282 - root - INFO - Starting Local AI Assistant
2025-03-17 16:16:18,282 - root - INFO - Initializing model manager
2025-03-17 16:16:18,365 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:16:18,365 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:16:18,366 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:16:18,367 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:16:18,367 - root - INFO - Initializing vector store
2025-03-17 16:16:18,396 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:16:18,458 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:16:18,458 - root - INFO - Initializing document loader
2025-03-17 16:16:18,462 - local_ai_assistant.document.loader - INFO - Loaded 5 documents from data/documents/documents.json
2025-03-17 16:16:18,462 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:16:18,469 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:16:18,469 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:16:18,469 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:16:18,472 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:16:18,490 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:16:18,490 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:16:18,491 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:16:18,492 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:16:18,518 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:26,185 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:16:26,204 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:26,221 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:26,237 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:34,786 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:16:34,812 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:34,828 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:34,834 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:16:37,159 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:16:37,174 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:37,186 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:37,199 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:46,023 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:16:46,041 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:46,052 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:46,058 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:16:46,059 - local_ai_assistant.cli.interface - INFO - Debug mode: False
2025-03-17 16:16:46,069 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:55,541 - root - INFO - Logging initialized
2025-03-17 16:16:55,541 - root - INFO - Starting Local AI Assistant
2025-03-17 16:16:55,541 - root - INFO - Initializing model manager
2025-03-17 16:16:55,620 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:16:55,620 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:16:55,621 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:16:55,621 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:16:55,621 - root - INFO - Initializing vector store
2025-03-17 16:16:55,647 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:16:55,702 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:16:55,702 - root - INFO - Initializing document loader
2025-03-17 16:16:55,706 - local_ai_assistant.document.loader - INFO - Loaded 5 documents from data/documents/documents.json
2025-03-17 16:16:55,706 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:16:55,713 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:16:55,713 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:16:55,713 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:16:55,717 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:16:56,106 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:16:56,125 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:56,136 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:56,148 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:16:58,802 - root - INFO - Logging initialized
2025-03-17 16:16:58,802 - root - INFO - Starting Local AI Assistant
2025-03-17 16:16:58,802 - root - INFO - Initializing model manager
2025-03-17 16:16:58,891 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:16:58,892 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:16:58,892 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:16:58,893 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:16:58,893 - root - INFO - Initializing vector store
2025-03-17 16:16:58,919 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:16:58,975 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:16:58,975 - root - INFO - Initializing document loader
2025-03-17 16:16:58,979 - local_ai_assistant.document.loader - INFO - Loaded 5 documents from data/documents/documents.json
2025-03-17 16:16:58,979 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:16:58,986 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:16:58,986 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:16:58,986 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:16:58,988 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:16:58,989 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:01,097 - root - INFO - Logging initialized
2025-03-17 16:17:01,098 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:01,098 - root - INFO - Initializing model manager
2025-03-17 16:17:01,191 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:01,191 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:01,192 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:01,192 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:01,192 - root - INFO - Initializing vector store
2025-03-17 16:17:01,218 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:01,277 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:01,277 - root - INFO - Initializing document loader
2025-03-17 16:17:01,281 - local_ai_assistant.document.loader - INFO - Loaded 5 documents from data/documents/documents.json
2025-03-17 16:17:01,281 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:01,288 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:01,288 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:01,288 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:01,290 - local_ai_assistant.cli.interface - INFO - Thinking display: False
2025-03-17 16:17:01,291 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:03,364 - root - INFO - Logging initialized
2025-03-17 16:17:03,364 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:03,364 - root - INFO - Initializing model manager
2025-03-17 16:17:03,450 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:03,450 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:03,451 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:03,451 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:03,451 - root - INFO - Initializing vector store
2025-03-17 16:17:03,481 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:03,543 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:03,543 - root - INFO - Initializing document loader
2025-03-17 16:17:03,547 - local_ai_assistant.document.loader - INFO - Loaded 5 documents from data/documents/documents.json
2025-03-17 16:17:03,547 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:03,555 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:03,555 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:03,555 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:03,558 - local_ai_assistant.cli.interface - INFO - Debug mode: True
2025-03-17 16:17:03,558 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:05,630 - root - INFO - Logging initialized
2025-03-17 16:17:05,630 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:05,630 - root - INFO - Initializing model manager
2025-03-17 16:17:05,715 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:05,715 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:05,716 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:05,716 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:05,716 - root - INFO - Initializing vector store
2025-03-17 16:17:05,743 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:05,802 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:05,802 - root - INFO - Initializing document loader
2025-03-17 16:17:05,806 - local_ai_assistant.document.loader - INFO - Loaded 5 documents from data/documents/documents.json
2025-03-17 16:17:05,806 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:05,813 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:05,813 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:05,813 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:05,815 - local_ai_assistant.cli.interface - INFO - Debug mode: False
2025-03-17 16:17:05,816 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:06,440 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:17:06,458 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:06,470 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:06,490 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:07,814 - root - INFO - Logging initialized
2025-03-17 16:17:07,814 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:07,814 - root - INFO - Initializing model manager
2025-03-17 16:17:07,898 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:07,898 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:07,899 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:07,899 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:07,899 - root - INFO - Initializing vector store
2025-03-17 16:17:07,924 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:07,979 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:07,979 - root - INFO - Initializing document loader
2025-03-17 16:17:07,983 - local_ai_assistant.document.loader - INFO - Loaded 5 documents from data/documents/documents.json
2025-03-17 16:17:07,983 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:07,989 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:07,989 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:07,989 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:07,993 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:07,993 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:10,012 - root - INFO - Logging initialized
2025-03-17 16:17:10,013 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:10,013 - root - INFO - Initializing model manager
2025-03-17 16:17:10,104 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:10,105 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:10,105 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:10,106 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:10,106 - root - INFO - Initializing vector store
2025-03-17 16:17:10,130 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:10,186 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:10,187 - root - INFO - Initializing document loader
2025-03-17 16:17:10,190 - local_ai_assistant.document.loader - INFO - Loaded 5 documents from data/documents/documents.json
2025-03-17 16:17:10,190 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:10,196 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:10,196 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:10,196 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:10,199 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:12,483 - root - INFO - Logging initialized
2025-03-17 16:17:12,483 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:12,483 - root - INFO - Initializing model manager
2025-03-17 16:17:12,567 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:12,567 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:12,568 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:12,568 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:12,568 - root - INFO - Initializing vector store
2025-03-17 16:17:12,596 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:12,657 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:12,657 - root - INFO - Initializing document loader
2025-03-17 16:17:12,661 - local_ai_assistant.document.loader - INFO - Loaded 5 documents from data/documents/documents.json
2025-03-17 16:17:12,661 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:12,668 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:12,669 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:12,669 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:12,671 - local_ai_assistant.cli.interface - INFO - Loading document: test_document.txt
2025-03-17 16:17:12,672 - local_ai_assistant.document.loader - INFO - Loaded document: test_document.txt (ID: 7158cf8a-9080-4a93-a9b3-b14b14c8c652)
2025-03-17 16:17:12,676 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:17:12,677 - local_ai_assistant.document.indexer - INFO - Created 1 chunks from document
2025-03-17 16:17:12,710 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:12,723 - local_ai_assistant.document.indexer - INFO - Indexed document 7158cf8a-9080-4a93-a9b3-b14b14c8c652 with 1 chunks
2025-03-17 16:17:12,724 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:14,840 - root - INFO - Logging initialized
2025-03-17 16:17:14,840 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:14,840 - root - INFO - Initializing model manager
2025-03-17 16:17:14,924 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:14,925 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:14,926 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:14,926 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:14,926 - root - INFO - Initializing vector store
2025-03-17 16:17:14,955 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:15,021 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:15,021 - root - INFO - Initializing document loader
2025-03-17 16:17:15,025 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:17:15,025 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:15,032 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:15,033 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:15,033 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:15,036 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:17,092 - root - INFO - Logging initialized
2025-03-17 16:17:17,092 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:17,092 - root - INFO - Initializing model manager
2025-03-17 16:17:17,177 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:17,177 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:17,178 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:17,178 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:17,178 - root - INFO - Initializing vector store
2025-03-17 16:17:17,207 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:17,270 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:17,271 - root - INFO - Initializing document loader
2025-03-17 16:17:17,275 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:17:17,275 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:17,282 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:17,282 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:17,282 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:17,297 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:18,950 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:17:18,970 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:18,984 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:18,998 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:19,420 - root - INFO - Logging initialized
2025-03-17 16:17:19,420 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:19,420 - root - INFO - Initializing model manager
2025-03-17 16:17:19,505 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:19,505 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:19,506 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:19,506 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:19,506 - root - INFO - Initializing vector store
2025-03-17 16:17:19,533 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:19,591 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:19,591 - root - INFO - Initializing document loader
2025-03-17 16:17:19,594 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:17:19,594 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:19,601 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:19,601 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:19,601 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:19,604 - local_ai_assistant.cli.interface - INFO - Thinking display: False
2025-03-17 16:17:19,604 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:21,779 - root - INFO - Logging initialized
2025-03-17 16:17:21,779 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:21,779 - root - INFO - Initializing model manager
2025-03-17 16:17:21,858 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:21,858 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:21,859 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:21,859 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:21,859 - root - INFO - Initializing vector store
2025-03-17 16:17:21,884 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:21,941 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:21,941 - root - INFO - Initializing document loader
2025-03-17 16:17:21,944 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:17:21,944 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:21,951 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:21,951 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:21,951 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:21,972 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:21,972 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:21,973 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:21,973 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:22,039 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:43,081 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:17:43,104 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:43,124 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:43,144 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:52,896 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:17:52,922 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:52,951 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:17:52,962 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:17:54,989 - root - INFO - Logging initialized
2025-03-17 16:17:54,989 - root - INFO - Starting Local AI Assistant
2025-03-17 16:17:54,989 - root - INFO - Initializing model manager
2025-03-17 16:17:55,101 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:55,101 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:55,102 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:55,103 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:55,103 - root - INFO - Initializing vector store
2025-03-17 16:17:55,142 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:17:55,227 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:17:55,227 - root - INFO - Initializing document loader
2025-03-17 16:17:55,233 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:17:55,233 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:17:55,244 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:17:55,244 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:17:55,244 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:17:55,278 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:55,279 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:17:55,280 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:17:55,280 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:17:55,315 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:18:11,203 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:18:11,223 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:18:11,250 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:18:11,259 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:18:24,129 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:18:24,147 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:18:24,170 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:18:24,176 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:18:25,973 - root - INFO - Logging initialized
2025-03-17 16:18:25,973 - root - INFO - Starting Local AI Assistant
2025-03-17 16:18:25,973 - root - INFO - Initializing model manager
2025-03-17 16:18:26,058 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:18:26,059 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:18:26,064 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:18:26,064 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:18:26,064 - root - INFO - Initializing vector store
2025-03-17 16:18:26,091 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:18:26,147 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:18:26,147 - root - INFO - Initializing document loader
2025-03-17 16:18:26,151 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:18:26,151 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:18:26,158 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:18:26,158 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:18:26,158 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:18:26,183 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:18:26,183 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:18:26,186 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:18:26,186 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:18:26,239 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:18:49,135 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:18:49,155 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:18:49,179 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:18:49,190 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:18:50,886 - root - INFO - Logging initialized
2025-03-17 16:18:50,886 - root - INFO - Starting Local AI Assistant
2025-03-17 16:18:50,886 - root - INFO - Initializing model manager
2025-03-17 16:18:50,966 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:18:50,967 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:18:50,969 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:18:50,969 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:18:50,969 - root - INFO - Initializing vector store
2025-03-17 16:18:50,996 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:18:51,050 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:18:51,051 - root - INFO - Initializing document loader
2025-03-17 16:18:51,054 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:18:51,054 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:18:51,060 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:18:51,061 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:18:51,061 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:18:51,084 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:18:51,085 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:18:51,087 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:18:51,087 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:18:51,133 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:19:15,499 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:19:15,524 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:19:15,545 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:19:15,553 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:19:17,357 - root - INFO - Logging initialized
2025-03-17 16:19:17,357 - root - INFO - Starting Local AI Assistant
2025-03-17 16:19:17,357 - root - INFO - Initializing model manager
2025-03-17 16:19:17,440 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:17,441 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:19:17,444 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:17,445 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:19:17,445 - root - INFO - Initializing vector store
2025-03-17 16:19:17,471 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:19:17,525 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:19:17,525 - root - INFO - Initializing document loader
2025-03-17 16:19:17,529 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:19:17,529 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:19:17,535 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:19:17,535 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:19:17,535 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:19:17,558 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:17,558 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:19:17,562 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:17,562 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:19:17,618 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:19:42,152 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:19:42,174 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:19:42,198 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:19:42,206 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:19:44,323 - root - INFO - Logging initialized
2025-03-17 16:19:44,323 - root - INFO - Starting Local AI Assistant
2025-03-17 16:19:44,323 - root - INFO - Initializing model manager
2025-03-17 16:19:44,402 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:44,402 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:19:44,404 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:44,404 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:19:44,404 - root - INFO - Initializing vector store
2025-03-17 16:19:44,430 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:19:44,486 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:19:44,486 - root - INFO - Initializing document loader
2025-03-17 16:19:44,490 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:19:44,490 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:19:44,497 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:19:44,497 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:19:44,497 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:19:44,499 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:19:44,500 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:19:46,572 - root - INFO - Logging initialized
2025-03-17 16:19:46,572 - root - INFO - Starting Local AI Assistant
2025-03-17 16:19:46,572 - root - INFO - Initializing model manager
2025-03-17 16:19:46,657 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:46,657 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:19:46,659 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:46,659 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:19:46,659 - root - INFO - Initializing vector store
2025-03-17 16:19:46,685 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:19:46,738 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:19:46,738 - root - INFO - Initializing document loader
2025-03-17 16:19:46,742 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:19:46,742 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:19:46,748 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:19:46,748 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:19:46,748 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:19:46,774 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:46,774 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:19:46,777 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:19:46,777 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:19:46,811 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:08,111 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:20:08,133 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:08,151 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:08,163 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:20:09,952 - root - INFO - Logging initialized
2025-03-17 16:20:09,953 - root - INFO - Starting Local AI Assistant
2025-03-17 16:20:09,953 - root - INFO - Initializing model manager
2025-03-17 16:20:10,028 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:10,029 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:20:10,032 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:10,033 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:20:10,033 - root - INFO - Initializing vector store
2025-03-17 16:20:10,057 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:20:10,109 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:20:10,109 - root - INFO - Initializing document loader
2025-03-17 16:20:10,113 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:20:10,113 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:20:10,119 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:20:10,119 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:20:10,119 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:20:10,142 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:10,142 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:20:10,144 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:10,144 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:20:10,216 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:23,253 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:20:23,274 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:23,289 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:23,295 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:20:25,188 - root - INFO - Logging initialized
2025-03-17 16:20:25,188 - root - INFO - Starting Local AI Assistant
2025-03-17 16:20:25,188 - root - INFO - Initializing model manager
2025-03-17 16:20:25,265 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:25,265 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:20:25,268 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:25,268 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:20:25,268 - root - INFO - Initializing vector store
2025-03-17 16:20:25,293 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:20:25,345 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:20:25,345 - root - INFO - Initializing document loader
2025-03-17 16:20:25,348 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:20:25,348 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:20:25,354 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:20:25,354 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:20:25,354 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:20:25,378 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:25,378 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:20:25,382 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:25,382 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:20:25,439 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:29,870 - root - INFO - Logging initialized
2025-03-17 16:20:29,870 - root - INFO - Starting Local AI Assistant
2025-03-17 16:20:29,871 - root - INFO - Initializing model manager
2025-03-17 16:20:29,964 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:29,964 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:20:29,965 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:29,965 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:20:29,965 - root - INFO - Initializing vector store
2025-03-17 16:20:29,992 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:20:30,049 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:20:30,049 - root - INFO - Initializing document loader
2025-03-17 16:20:30,053 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:20:30,053 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:20:30,060 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:20:30,060 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:20:30,060 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:20:30,063 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:20:30,083 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:30,084 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:20:30,085 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:30,085 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:20:30,109 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:46,743 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:20:46,770 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:46,788 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:46,795 - local_ai_assistant.cli.interface - INFO - Thinking display: False
2025-03-17 16:20:46,819 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:51,755 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:20:51,798 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:51,842 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:20:51,851 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:20:53,637 - root - INFO - Logging initialized
2025-03-17 16:20:53,637 - root - INFO - Starting Local AI Assistant
2025-03-17 16:20:53,637 - root - INFO - Initializing model manager
2025-03-17 16:20:53,722 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:53,723 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:20:53,724 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:53,724 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:20:53,724 - root - INFO - Initializing vector store
2025-03-17 16:20:53,753 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:20:53,815 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:20:53,815 - root - INFO - Initializing document loader
2025-03-17 16:20:53,819 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:20:53,819 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:20:53,826 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:20:53,826 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:20:53,826 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:20:53,850 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:53,851 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:20:53,851 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:20:53,852 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:20:53,885 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:06,252 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:21:06,277 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:06,295 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:06,301 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:21:12,427 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:21:12,444 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:12,461 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:12,468 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:21:17,517 - root - INFO - Logging initialized
2025-03-17 16:21:17,517 - root - INFO - Starting Local AI Assistant
2025-03-17 16:21:17,517 - root - INFO - Initializing model manager
2025-03-17 16:21:17,602 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:17,602 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:21:17,604 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:17,605 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:21:17,605 - root - INFO - Initializing vector store
2025-03-17 16:21:17,631 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:21:17,683 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:21:17,684 - root - INFO - Initializing document loader
2025-03-17 16:21:17,687 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:21:17,687 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:21:17,693 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:21:17,693 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:21:17,693 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:21:17,717 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:17,717 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:21:17,719 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:17,719 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:21:17,761 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:31,879 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:21:31,902 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:31,918 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:31,927 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:21:33,742 - root - INFO - Logging initialized
2025-03-17 16:21:33,742 - root - INFO - Starting Local AI Assistant
2025-03-17 16:21:33,742 - root - INFO - Initializing model manager
2025-03-17 16:21:33,825 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:33,825 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:21:33,828 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:33,828 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:21:33,828 - root - INFO - Initializing vector store
2025-03-17 16:21:33,852 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:21:33,906 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:21:33,906 - root - INFO - Initializing document loader
2025-03-17 16:21:33,910 - local_ai_assistant.document.loader - INFO - Loaded 6 documents from data/documents/documents.json
2025-03-17 16:21:33,910 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:21:33,916 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:21:33,916 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:21:33,916 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:21:33,919 - local_ai_assistant.cli.interface - INFO - Loading document: test_document.txt
2025-03-17 16:21:33,920 - local_ai_assistant.document.loader - INFO - Loaded document: test_document.txt (ID: 00bc5a70-6a9e-445e-8e4c-86c9495d997a)
2025-03-17 16:21:33,923 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:21:33,924 - local_ai_assistant.document.indexer - INFO - Created 1 chunks from document
2025-03-17 16:21:33,976 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:33,991 - local_ai_assistant.document.indexer - INFO - Indexed document 00bc5a70-6a9e-445e-8e4c-86c9495d997a with 1 chunks
2025-03-17 16:21:34,001 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:34,001 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:21:34,003 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:34,003 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:21:34,021 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:38,696 - root - INFO - Logging initialized
2025-03-17 16:21:38,696 - root - INFO - Starting Local AI Assistant
2025-03-17 16:21:38,696 - root - INFO - Initializing model manager
2025-03-17 16:21:38,779 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:38,779 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:21:38,780 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:21:38,780 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:21:38,780 - root - INFO - Initializing vector store
2025-03-17 16:21:38,808 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:21:38,869 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:21:38,869 - root - INFO - Initializing document loader
2025-03-17 16:21:38,873 - local_ai_assistant.document.loader - INFO - Loaded 7 documents from data/documents/documents.json
2025-03-17 16:21:38,873 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:21:38,881 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:21:38,881 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:21:38,881 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:21:38,884 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:21:38,884 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:21:46,728 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:21:46,749 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:46,765 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:21:46,773 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:22:06,135 - root - INFO - Logging initialized
2025-03-17 16:22:06,137 - root - INFO - Starting Local AI Assistant
2025-03-17 16:22:06,137 - root - INFO - Initializing model manager
2025-03-17 16:22:06,217 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:22:06,217 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:22:06,220 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:22:06,220 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:22:06,220 - root - INFO - Initializing vector store
2025-03-17 16:22:06,245 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:22:06,301 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:22:06,301 - root - INFO - Initializing document loader
2025-03-17 16:22:06,305 - local_ai_assistant.document.loader - INFO - Loaded 7 documents from data/documents/documents.json
2025-03-17 16:22:06,305 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:22:06,311 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:22:06,311 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:22:06,312 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:22:06,314 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:22:06,335 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:22:06,335 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:22:06,337 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:22:06,337 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:22:06,373 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:22:22,863 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:22:22,883 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:22:22,898 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:22:22,905 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:22:44,133 - root - INFO - Logging initialized
2025-03-17 16:22:44,133 - root - INFO - Starting Local AI Assistant
2025-03-17 16:22:44,133 - root - INFO - Initializing model manager
2025-03-17 16:22:44,210 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:22:44,210 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:22:44,215 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:22:44,215 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:22:44,215 - root - INFO - Initializing vector store
2025-03-17 16:22:44,241 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:22:44,295 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:22:44,296 - root - INFO - Initializing document loader
2025-03-17 16:22:44,299 - local_ai_assistant.document.loader - INFO - Loaded 7 documents from data/documents/documents.json
2025-03-17 16:22:44,299 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:22:44,305 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:22:44,305 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:22:44,305 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:22:44,329 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:22:44,329 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:22:44,332 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:22:44,332 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:22:44,371 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:29:35,710 - root - INFO - Logging initialized
2025-03-17 16:29:35,710 - root - INFO - Starting Local AI Assistant
2025-03-17 16:29:35,710 - root - INFO - Initializing model manager
2025-03-17 16:29:35,785 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:29:35,786 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:29:35,789 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:29:35,789 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:29:35,789 - root - INFO - Initializing vector store
2025-03-17 16:29:35,813 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:29:35,862 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:29:35,862 - root - INFO - Initializing document loader
2025-03-17 16:29:35,865 - local_ai_assistant.document.loader - INFO - Loaded 7 documents from data/documents/documents.json
2025-03-17 16:29:35,865 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:29:35,871 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:29:35,872 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:29:35,872 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:29:46,858 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:29:46,858 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:29:46,861 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:29:46,862 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:29:47,197 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:29:59,298 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:29:59,321 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:29:59,333 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:30:20,083 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:30:31,428 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:30:31,447 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:30:31,460 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:30:51,142 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:31:06,606 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:31:06,628 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:31:06,645 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:31:59,076 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:32:04,630 - root - INFO - Logging initialized
2025-03-17 16:32:04,630 - root - INFO - Starting Local AI Assistant
2025-03-17 16:32:04,630 - root - INFO - Initializing model manager
2025-03-17 16:32:04,733 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:32:04,733 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:32:04,735 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:32:04,735 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:32:04,735 - root - INFO - Initializing vector store
2025-03-17 16:32:04,760 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:32:04,812 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:32:04,812 - root - INFO - Initializing document loader
2025-03-17 16:32:04,815 - local_ai_assistant.document.loader - INFO - Loaded 7 documents from data/documents/documents.json
2025-03-17 16:32:04,815 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt']
2025-03-17 16:32:04,821 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:32:04,821 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:32:04,821 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:32:28,608 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:32:28,610 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:32:28,612 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:32:28,612 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:32:28,651 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:33:00,194 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:33:00,217 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:33:00,249 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:33:29,733 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:33:36,727 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:34:08,723 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:34:08,748 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:34:08,777 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:41:45,913 - local_ai_assistant.cli.interface - INFO - Loading document: local_ai_assistant/memory/PDF/bazi .rtf
2025-03-17 16:41:45,915 - local_ai_assistant.document.loader - ERROR - Unsupported file format: rtf
2025-03-17 16:41:58,114 - local_ai_assistant.cli.interface - INFO - Loading document: local_ai_assistant/memory/PDF/my bazi yearly summaries.rtf
2025-03-17 16:41:58,115 - local_ai_assistant.document.loader - ERROR - Unsupported file format: rtf
2025-03-17 16:42:08,873 - local_ai_assistant.cli.interface - INFO - Loading document: local_ai_assistant/memory/PDF/meaning of life from medium a.rtf
2025-03-17 16:42:08,875 - local_ai_assistant.document.loader - ERROR - Unsupported file format: rtf
2025-03-17 16:48:02,304 - root - INFO - Logging initialized
2025-03-17 16:48:02,304 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:02,304 - root - INFO - Initializing model manager
2025-03-17 16:48:02,382 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:02,382 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:02,384 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:02,385 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:02,385 - root - INFO - Initializing vector store
2025-03-17 16:48:02,408 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:02,459 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:02,459 - root - INFO - Initializing document loader
2025-03-17 16:48:02,462 - local_ai_assistant.document.loader - INFO - Loaded 7 documents from data/documents/documents.json
2025-03-17 16:48:02,463 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:02,468 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:02,469 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:02,469 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:02,471 - local_ai_assistant.cli.interface - INFO - Loading document: test_document.rtf
2025-03-17 16:48:02,473 - local_ai_assistant.document.loader - INFO - Loaded document: test_document.rtf (ID: 04798e78-22e7-4831-9eb4-550aaadf8d1f)
2025-03-17 16:48:02,477 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:48:02,477 - local_ai_assistant.document.indexer - INFO - Created 1 chunks from document
2025-03-17 16:48:02,806 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:48:02,830 - local_ai_assistant.document.indexer - INFO - Indexed document 04798e78-22e7-4831-9eb4-550aaadf8d1f with 1 chunks
2025-03-17 16:48:02,832 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:21,245 - root - INFO - Logging initialized
2025-03-17 16:48:21,245 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:21,245 - root - INFO - Initializing model manager
2025-03-17 16:48:21,321 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:21,321 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:21,323 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:21,323 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:21,323 - root - INFO - Initializing vector store
2025-03-17 16:48:21,347 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:21,398 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:21,398 - root - INFO - Initializing document loader
2025-03-17 16:48:21,401 - local_ai_assistant.document.loader - INFO - Loaded 8 documents from data/documents/documents.json
2025-03-17 16:48:21,401 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:21,407 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:21,407 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:21,408 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:21,412 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:23,453 - root - INFO - Logging initialized
2025-03-17 16:48:23,453 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:23,453 - root - INFO - Initializing model manager
2025-03-17 16:48:23,543 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:23,543 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:23,548 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:23,548 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:23,548 - root - INFO - Initializing vector store
2025-03-17 16:48:23,570 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:23,620 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:23,620 - root - INFO - Initializing document loader
2025-03-17 16:48:23,623 - local_ai_assistant.document.loader - INFO - Loaded 8 documents from data/documents/documents.json
2025-03-17 16:48:23,623 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:23,629 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:23,629 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:23,629 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:23,635 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:23,635 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:25,610 - root - INFO - Logging initialized
2025-03-17 16:48:25,610 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:25,610 - root - INFO - Initializing model manager
2025-03-17 16:48:25,703 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:25,703 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:25,707 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:25,707 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:25,707 - root - INFO - Initializing vector store
2025-03-17 16:48:25,730 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:25,779 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:25,779 - root - INFO - Initializing document loader
2025-03-17 16:48:25,782 - local_ai_assistant.document.loader - INFO - Loaded 8 documents from data/documents/documents.json
2025-03-17 16:48:25,782 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:25,788 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:25,788 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:25,788 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:25,790 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:27,871 - root - INFO - Logging initialized
2025-03-17 16:48:27,872 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:27,872 - root - INFO - Initializing model manager
2025-03-17 16:48:27,944 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:27,944 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:27,948 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:27,948 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:27,948 - root - INFO - Initializing vector store
2025-03-17 16:48:27,971 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:28,024 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:28,024 - root - INFO - Initializing document loader
2025-03-17 16:48:28,028 - local_ai_assistant.document.loader - INFO - Loaded 8 documents from data/documents/documents.json
2025-03-17 16:48:28,028 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:28,035 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:28,035 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:28,035 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:28,054 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:30,161 - root - INFO - Logging initialized
2025-03-17 16:48:30,161 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:30,161 - root - INFO - Initializing model manager
2025-03-17 16:48:30,239 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:30,239 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:30,246 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:30,247 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:30,247 - root - INFO - Initializing vector store
2025-03-17 16:48:30,269 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:30,319 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:30,319 - root - INFO - Initializing document loader
2025-03-17 16:48:30,323 - local_ai_assistant.document.loader - INFO - Loaded 8 documents from data/documents/documents.json
2025-03-17 16:48:30,323 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:30,329 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:30,329 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:30,329 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:30,331 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:32,361 - root - INFO - Logging initialized
2025-03-17 16:48:32,362 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:32,362 - root - INFO - Initializing model manager
2025-03-17 16:48:32,437 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:32,438 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:32,441 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:32,441 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:32,441 - root - INFO - Initializing vector store
2025-03-17 16:48:32,464 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:32,514 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:32,514 - root - INFO - Initializing document loader
2025-03-17 16:48:32,517 - local_ai_assistant.document.loader - INFO - Loaded 8 documents from data/documents/documents.json
2025-03-17 16:48:32,517 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:32,523 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:32,523 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:32,523 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:32,526 - local_ai_assistant.cli.interface - INFO - Thinking display: True
2025-03-17 16:48:32,526 - local_ai_assistant.cli.interface - INFO - Thinking display: False
2025-03-17 16:48:32,526 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:34,598 - root - INFO - Logging initialized
2025-03-17 16:48:34,598 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:34,599 - root - INFO - Initializing model manager
2025-03-17 16:48:34,674 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:34,674 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:34,677 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:34,677 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:34,677 - root - INFO - Initializing vector store
2025-03-17 16:48:34,699 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:34,749 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:34,749 - root - INFO - Initializing document loader
2025-03-17 16:48:34,753 - local_ai_assistant.document.loader - INFO - Loaded 8 documents from data/documents/documents.json
2025-03-17 16:48:34,753 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:34,759 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:34,759 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:34,759 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:34,761 - local_ai_assistant.cli.interface - INFO - Debug mode: False
2025-03-17 16:48:34,764 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:34,764 - local_ai_assistant.cli.interface - INFO - Debug mode: True
2025-03-17 16:48:34,764 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:36,712 - root - INFO - Logging initialized
2025-03-17 16:48:36,712 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:36,712 - root - INFO - Initializing model manager
2025-03-17 16:48:36,786 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:36,786 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:36,788 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:36,788 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:36,788 - root - INFO - Initializing vector store
2025-03-17 16:48:36,810 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:36,860 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:36,860 - root - INFO - Initializing document loader
2025-03-17 16:48:36,864 - local_ai_assistant.document.loader - INFO - Loaded 8 documents from data/documents/documents.json
2025-03-17 16:48:36,864 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:36,870 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:36,870 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:36,870 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:36,872 - local_ai_assistant.cli.interface - INFO - Switching to model: gemma3:27b
2025-03-17 16:48:36,876 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:36,876 - local_ai_assistant.models.model_manager - INFO - Switched to model: gemma3:27b
2025-03-17 16:48:36,877 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:38,884 - root - INFO - Logging initialized
2025-03-17 16:48:38,884 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:38,884 - root - INFO - Initializing model manager
2025-03-17 16:48:38,964 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:38,964 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:38,967 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:38,967 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:38,967 - root - INFO - Initializing vector store
2025-03-17 16:48:38,989 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:39,039 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:39,039 - root - INFO - Initializing document loader
2025-03-17 16:48:39,042 - local_ai_assistant.document.loader - INFO - Loaded 8 documents from data/documents/documents.json
2025-03-17 16:48:39,042 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:39,048 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:39,048 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:39,048 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:39,050 - local_ai_assistant.cli.interface - INFO - Loading document: test_document.rtf
2025-03-17 16:48:39,051 - local_ai_assistant.document.loader - INFO - Loaded document: test_document.rtf (ID: b9ec2757-c900-46e4-8220-d164b455325c)
2025-03-17 16:48:39,055 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:48:39,055 - local_ai_assistant.document.indexer - INFO - Created 1 chunks from document
2025-03-17 16:48:39,100 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:48:39,114 - local_ai_assistant.document.indexer - INFO - Indexed document b9ec2757-c900-46e4-8220-d164b455325c with 1 chunks
2025-03-17 16:48:39,115 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:41,040 - root - INFO - Logging initialized
2025-03-17 16:48:41,041 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:41,041 - root - INFO - Initializing model manager
2025-03-17 16:48:41,118 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:41,119 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:41,121 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:41,121 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:41,121 - root - INFO - Initializing vector store
2025-03-17 16:48:41,144 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:41,195 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:41,195 - root - INFO - Initializing document loader
2025-03-17 16:48:41,199 - local_ai_assistant.document.loader - INFO - Loaded 9 documents from data/documents/documents.json
2025-03-17 16:48:41,199 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:41,205 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:41,205 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:41,205 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:41,213 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:48:43,189 - root - INFO - Logging initialized
2025-03-17 16:48:43,189 - root - INFO - Starting Local AI Assistant
2025-03-17 16:48:43,189 - root - INFO - Initializing model manager
2025-03-17 16:48:43,277 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:43,277 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:43,280 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:43,280 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:43,280 - root - INFO - Initializing vector store
2025-03-17 16:48:43,303 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:48:43,353 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:48:43,353 - root - INFO - Initializing document loader
2025-03-17 16:48:43,357 - local_ai_assistant.document.loader - INFO - Loaded 9 documents from data/documents/documents.json
2025-03-17 16:48:43,357 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:48:43,363 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:48:43,363 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:48:43,363 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:48:43,387 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:43,387 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:48:43,389 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:48:43,389 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:48:43,423 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:49:16,103 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:49:16,128 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:49:16,160 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:49:16,167 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:49:17,864 - root - INFO - Logging initialized
2025-03-17 16:49:17,864 - root - INFO - Starting Local AI Assistant
2025-03-17 16:49:17,864 - root - INFO - Initializing model manager
2025-03-17 16:49:17,942 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:49:17,943 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:49:17,945 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:49:17,945 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:49:17,945 - root - INFO - Initializing vector store
2025-03-17 16:49:17,980 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:49:18,039 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:49:18,040 - root - INFO - Initializing document loader
2025-03-17 16:49:18,043 - local_ai_assistant.document.loader - INFO - Loaded 9 documents from data/documents/documents.json
2025-03-17 16:49:18,043 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:49:18,049 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:49:18,049 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:49:18,049 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:49:18,073 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:49:18,073 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:49:18,076 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:49:18,077 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:49:18,127 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:49:31,209 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:49:31,228 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:49:31,240 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:49:31,249 - local_ai_assistant.models.model_manager - INFO - Shutting down model manager
2025-03-17 16:50:17,622 - root - INFO - Logging initialized
2025-03-17 16:50:17,622 - root - INFO - Starting Local AI Assistant
2025-03-17 16:50:17,622 - root - INFO - Initializing model manager
2025-03-17 16:50:17,715 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:50:17,715 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:50:17,718 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:50:17,718 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:50:17,718 - root - INFO - Initializing vector store
2025-03-17 16:50:17,742 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 16:50:17,794 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 16:50:17,794 - root - INFO - Initializing document loader
2025-03-17 16:50:17,798 - local_ai_assistant.document.loader - INFO - Loaded 9 documents from data/documents/documents.json
2025-03-17 16:50:17,798 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 16:50:17,804 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 16:50:17,804 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 16:50:17,804 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 16:50:31,474 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:50:31,475 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 16:50:31,478 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 16:50:31,478 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 16:50:31,521 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:50:48,418 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:50:48,436 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:50:48,451 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:51:14,580 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:51:37,438 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:51:37,458 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:51:37,482 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,405 - local_ai_assistant.cli.interface - INFO - Loading document: local_ai_assistant/memory/PDF/bazi .rtf
2025-03-17 16:52:03,428 - local_ai_assistant.document.loader - INFO - Loaded document: bazi .rtf (ID: 957beec2-c1f2-4162-9d30-4621c4e6eb1b)
2025-03-17 16:52:03,434 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:52:03,434 - local_ai_assistant.document.indexer - INFO - Created 81 chunks from document
2025-03-17 16:52:03,480 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,493 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,518 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,530 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,541 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,564 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,574 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,585 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,611 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,621 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,631 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,650 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,667 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,682 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,694 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,709 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,726 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,741 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,753 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,768 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,785 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,799 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,814 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,826 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,843 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,858 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,874 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,890 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,905 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,916 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,934 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,950 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,965 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:03,982 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,002 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,014 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,033 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,050 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,066 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,083 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,099 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,110 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,127 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,148 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,163 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,184 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,196 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,211 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,227 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,243 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,254 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,271 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,287 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,301 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,316 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,332 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,342 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,357 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,371 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,381 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,396 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,412 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,421 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,438 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,450 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,468 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,484 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,503 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,517 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,530 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,545 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,560 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,577 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,591 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,600 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,616 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,630 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,647 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,662 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,678 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,690 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:04,829 - local_ai_assistant.document.indexer - INFO - Indexed document 957beec2-c1f2-4162-9d30-4621c4e6eb1b with 81 chunks
2025-03-17 16:52:12,488 - local_ai_assistant.cli.interface - INFO - Loading document: local_ai_assistant/memory/PDF/meaning of life from medium a.rtf
2025-03-17 16:52:12,496 - local_ai_assistant.document.loader - INFO - Loaded document: meaning of life from medium a.rtf (ID: 5cbb1b78-3015-482d-84ff-96fab6616e07)
2025-03-17 16:52:12,499 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:52:12,500 - local_ai_assistant.document.indexer - INFO - Created 19 chunks from document
2025-03-17 16:52:12,543 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,572 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,584 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,598 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,622 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,633 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,643 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,666 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,677 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,688 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,704 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,714 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,729 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,745 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,762 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,778 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,792 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,808 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,823 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:12,864 - local_ai_assistant.document.indexer - INFO - Indexed document 5cbb1b78-3015-482d-84ff-96fab6616e07 with 19 chunks
2025-03-17 16:52:18,835 - local_ai_assistant.cli.interface - INFO - Loading document: local_ai_assistant/memory/PDF/my bazi yearly summaries.rtf
2025-03-17 16:52:18,880 - local_ai_assistant.document.loader - INFO - Loaded document: my bazi yearly summaries.rtf (ID: d417796e-2feb-4cde-bacc-5b6058377c1e)
2025-03-17 16:52:18,884 - local_ai_assistant.document.indexer - INFO - Document indexer initialized
2025-03-17 16:52:18,885 - local_ai_assistant.document.indexer - INFO - Created 253 chunks from document
2025-03-17 16:52:18,928 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:18,941 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:18,973 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:18,989 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,014 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,023 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,033 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,053 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,063 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,079 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,095 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,106 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,120 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,135 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,153 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,168 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,180 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,192 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,203 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,213 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,230 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,242 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,264 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,281 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,298 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,310 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,325 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,341 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,355 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,371 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,392 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,414 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,429 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,441 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,459 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,478 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,495 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,514 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,533 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,546 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,560 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,576 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,591 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,608 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,618 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,636 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,653 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,672 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,691 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,712 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,730 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,751 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,765 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,783 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,794 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,811 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,828 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,843 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,853 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,870 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,879 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,892 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,905 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,913 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,929 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,948 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,965 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,983 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:19,999 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,009 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,025 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,039 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,054 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,068 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,079 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,092 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,110 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,124 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,140 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,157 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,172 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,187 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,200 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,218 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,237 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,256 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,272 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,286 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,297 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,315 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,332 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,353 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,372 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,392 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,410 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,429 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,446 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,465 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,485 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,504 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,524 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,538 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,551 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,564 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,576 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,589 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,602 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,613 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,625 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,637 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,647 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,661 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,688 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,698 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,710 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,722 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,733 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,744 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,755 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,767 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,778 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,790 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,802 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,816 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,830 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,844 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,857 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,870 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,903 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,916 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,929 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,943 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,956 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,967 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,979 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:20,992 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,004 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,016 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,029 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,041 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,070 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,083 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,095 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,128 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,137 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,147 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,159 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,169 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,181 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,193 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,205 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,217 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,228 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,240 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,268 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,281 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,294 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,305 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,318 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,330 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,343 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,356 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,372 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,385 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,396 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,409 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,419 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,429 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,440 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,450 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,463 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,474 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,484 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,494 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,504 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,513 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,525 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,534 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,544 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,553 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,563 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,571 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,583 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,593 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,604 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,615 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,625 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,635 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,644 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,655 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,665 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,675 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,685 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,696 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,708 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,718 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,729 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,740 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,749 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,760 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,772 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,786 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,798 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,810 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,823 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,838 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,855 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,872 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,885 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,896 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,908 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,921 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,933 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,944 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,956 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,967 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,980 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:21,993 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,018 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,030 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,040 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,066 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,075 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,087 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,114 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,127 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,140 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,167 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,181 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,195 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,210 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,222 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,236 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,250 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,262 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,291 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,302 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,321 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,331 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,343 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,353 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,363 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,372 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,382 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,391 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,400 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,410 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,419 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,429 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,439 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,447 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,457 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,464 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:52:22,916 - local_ai_assistant.document.indexer - INFO - Indexed document d417796e-2feb-4cde-bacc-5b6058377c1e with 253 chunks
2025-03-17 16:52:37,527 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:53:20,708 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:53:20,735 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:53:20,772 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:54:14,574 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:55:03,621 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 16:55:03,650 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 16:55:03,687 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 17:15:24,748 - root - INFO - Logging initialized
2025-03-17 17:15:24,748 - root - INFO - Starting Local AI Assistant
2025-03-17 17:15:24,748 - root - INFO - Initializing model manager
2025-03-17 17:15:24,837 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 17:15:24,838 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 17:15:24,840 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 17:15:24,841 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 17:15:24,841 - root - INFO - Initializing vector store
2025-03-17 17:15:24,864 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-03-17 17:15:24,914 - local_ai_assistant.memory.vector_store - INFO - ChromaDB initialized with collection: conversations
2025-03-17 17:15:24,914 - root - INFO - Initializing document loader
2025-03-17 17:15:24,918 - local_ai_assistant.document.loader - INFO - Loaded 12 documents from data/documents/documents.json
2025-03-17 17:15:24,918 - local_ai_assistant.document.loader - INFO - Document loader initialized, supported formats: ['pdf', 'txt', 'rtf']
2025-03-17 17:15:24,924 - local_ai_assistant.debug.response_analyzer - INFO - Response analyzer initialized, enabled: True
2025-03-17 17:15:24,924 - local_ai_assistant.cli.interface - INFO - CLI interface initialized
2025-03-17 17:15:24,924 - local_ai_assistant.cli.interface - INFO - Starting CLI interface
2025-03-17 17:17:26,821 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 17:17:26,821 - local_ai_assistant.models.model_manager - INFO - Ollama service is available
2025-03-17 17:17:26,823 - httpx - INFO - HTTP Request: GET http://127.0.0.1:11434/api/tags "HTTP/1.1 200 OK"
2025-03-17 17:17:26,823 - local_ai_assistant.models.model_manager - INFO - Loaded model: gemma3:27b
2025-03-17 17:17:27,160 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 17:18:01,226 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate "HTTP/1.1 200 OK"
2025-03-17 17:18:01,244 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
2025-03-17 17:18:01,268 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
